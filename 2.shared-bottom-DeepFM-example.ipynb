{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcNP6wnl8Yfq"
   },
   "source": [
    "# DeepFM建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6srBeg382ee"
   },
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kloudYEG6Cws"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "train = joblib.load('./data_and_feature/train.txt')\n",
    "val = joblib.load('./data_and_feature/val.txt')\n",
    "test = joblib.load('./data_and_feature/test.txt')\n",
    "encoder = joblib.load('./data_and_feature/encoder.txt')\n",
    "\n",
    "train_num = len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfVav1G3NM_Q"
   },
   "source": [
    "## 导入工具库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "atU3210yKot0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping\n",
    "\n",
    "from tensorflow.keras import optimizers,initializers\n",
    "from tensorflow.python.keras.initializers import glorot_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlJgKlOlNTcV"
   },
   "source": [
    "## 搭建DeepFM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "6FunCHvVMzKq"
   },
   "outputs": [],
   "source": [
    "class MeanPoolLayer(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(MeanPoolLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        mask = tf.expand_dims(tf.cast(mask,tf.float32),axis = -1)\n",
    "        x = x * mask\n",
    "        return K.sum(x, axis=self.axis) / (K.sum(mask, axis=self.axis) + 1e-9)\n",
    "\n",
    "def secondary_fm(W):\n",
    "    #先相加再平方。\n",
    "    frs_part = Add()(W)\n",
    "    frs_part = Multiply()([frs_part,frs_part]) \n",
    "    #先平方再相加\n",
    "    scd_part = Add()([Multiply()([_x,_x]) for _x in W])\n",
    "    #相减，乘0.5.\n",
    "    fm_part = Subtract()([frs_part,scd_part])\n",
    "    fm_part = Lambda(lambda x:K.sum(x,axis = 1,keepdims = True)*0.5)(fm_part)\n",
    "    return fm_part\n",
    "\n",
    "\n",
    "def build_FM(sparse_cols,dense_cols,sparse_max_len,embed_dim = 16, \n",
    "               dnn_hidden_units=(128, 128),varlens_cols = [],varlens_max_len = {},\n",
    "               dropout = 0,embedding_reg_l2 = 1e-6,dnn_reg_l2 = 0.0):\n",
    "    ''' \n",
    "    sparse_cols,dense_cols:离散变量名，连续变量名。\n",
    "    sparse_max_len：字典：离散变量对应的最大的取值范围。\n",
    "    varlens_cols:可变离散变量名。\n",
    "    varlens_max_len:可变离散变量的最大取值范围。\n",
    "    '''\n",
    "    \n",
    "    #输入部分，分为sparse,varlens,dense部分。\n",
    "    sparse_inputs = {f:Input([1],name = f) for f in sparse_cols}\n",
    "    dense_inputs = {f:Input([1],name = f) for f in dense_cols}\n",
    "    varlens_inputs = {f:Input([None,1],name = f) for f in varlens_cols}\n",
    "        \n",
    "    input_embed = {}\n",
    "    #离散特征，embedding到k维，得到其隐向量。wi\n",
    "    for f in sparse_cols:\n",
    "        _input = sparse_inputs[f]\n",
    "        embedding = Embedding(sparse_max_len[f], embed_dim, \n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg_l2)) \n",
    "        input_embed[f] =Flatten()(embedding(_input)) #(bs,k)\n",
    "        \n",
    "    #多标签离散变量\n",
    "    for f in varlens_inputs:\n",
    "        _input = varlens_inputs[f]\n",
    "        mask = Masking(mask_value = 0).compute_mask(_input)\n",
    "        embedding = Embedding(varlens_max_len[f], embed_dim,\n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(1e-6))\n",
    "        _embed =Reshape([-1,embed_dim])(embedding(_input))\n",
    "        out_embed = MeanPoolLayer(axis=1)(_embed,mask)\n",
    "        input_embed[f] = out_embed\n",
    "    \n",
    "    #连续变量\n",
    "    for f in dense_inputs:\n",
    "        _input = dense_inputs[f]\n",
    "        _embed = Dense(embed_dim,use_bias = False,activation = 'linear')(_input)\n",
    "        input_embed[f] = _embed\n",
    "        \n",
    "    feature_name =  sparse_cols+varlens_cols+dense_cols\n",
    "    fm_embed = [input_embed[f] for f in feature_name]\n",
    "    fm_part = secondary_fm(fm_embed)\n",
    "    \n",
    "    #离散变量和连续变量拼接成dnn feature\n",
    "    dnn_feature = Concatenate(axis = -1)(fm_embed)\n",
    "    for num in dnn_hidden_units:\n",
    "        dnn_feature = Dropout(dropout)(Dense(num,activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(dnn_reg_l2))(dnn_feature))\n",
    "        \n",
    "    dnn_output = Dense(1,activation = 'linear', kernel_regularizer=regularizers.l2(dnn_reg_l2),\n",
    "          use_bias = True)(dnn_feature)\n",
    "    logits = Activation('sigmoid')(Add()([fm_part,dnn_output]))\n",
    "    inputs = [sparse_inputs[f] for f in sparse_inputs]+[varlens_inputs[f] for f in varlens_inputs]\\\n",
    "                +[dense_inputs[f] for f in dense_inputs]\n",
    "    model = Model(inputs,logits) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bRpBQkEcNDBs",
    "outputId": "2bc19606-f2a4-4e12-e7ed-038cb7343e1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "656/656 [==============================] - 23s 28ms/step - loss: 0.1056 - auc: 0.9169 - val_loss: 0.1022 - val_auc: 0.9197\n",
      "Epoch 2/4\n",
      "656/656 [==============================] - 17s 25ms/step - loss: 0.0992 - auc: 0.9353 - val_loss: 0.1023 - val_auc: 0.9224\n",
      "Epoch 3/4\n",
      "656/656 [==============================] - 16s 25ms/step - loss: 0.0990 - auc: 0.9376 - val_loss: 0.1023 - val_auc: 0.9248\n",
      "Epoch 4/4\n",
      "656/656 [==============================] - 17s 25ms/step - loss: 0.0986 - auc: 0.9394 - val_loss: 0.1022 - val_auc: 0.9253\n"
     ]
    }
   ],
   "source": [
    "# 特征与标签\n",
    "target = [\"read_comment\", \"like\", \"click_avatar\", \"forward\"]\n",
    "sparse_features = ['userid', 'feedid', 'authorid', 'bgm_song_id', 'bgm_singer_id']\n",
    "varlen_features = ['manual_tag_list','manual_keyword_list']\n",
    "dense_features = ['videoplayseconds']\n",
    "\n",
    "# 生成输入特征设置\n",
    "sparse_max_len = {f:len(encoder[f]) + 1 for f in sparse_features}\n",
    "varlens_max_len = {f:len(encoder[f]) + 1 for f in varlen_features}\n",
    "feature_names = sparse_features+varlen_features+dense_features\n",
    "\n",
    "# 构建输入数据\n",
    "train_model_input = {name: train[name] if name not in varlen_features else np.stack(train[name]) for name in feature_names } #训练模型的输入，字典类型。名称和具体值\n",
    "val_model_input = {name: val[name] if name not in varlen_features else np.stack(val[name]) for name in feature_names }\n",
    "test_model_input = {name: test[name] if name not in varlen_features else np.stack(test[name]) for name in feature_names}\n",
    "\n",
    "train_labels = train['read_comment'].values\n",
    "val_labels = val['read_comment'].values\n",
    "\n",
    "# 多余的特征删除，释放内存\n",
    "del train,val \n",
    "gc.collect()\n",
    "\n",
    "model = build_FM(sparse_features,dense_features,sparse_max_len,embed_dim = 16, \n",
    "            dnn_hidden_units=(64,64),varlens_cols = varlen_features,varlens_max_len = varlens_max_len,\n",
    "            dropout = 0.1,embedding_reg_l2 = 1e-6,dnn_reg_l2 = 0.0)\n",
    "\n",
    "adam = optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(adam, loss = 'binary_crossentropy' ,metrics = [tf.keras.metrics.AUC()],)\n",
    "\n",
    "history = model.fit(train_model_input, train_labels,validation_data = (val_model_input,val_labels),\n",
    "                    batch_size=10240, epochs=4, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2.shared-bottom-DeepFM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
